{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbfb0f1e",
   "metadata": {},
   "source": [
    "# Machine learning\n",
    "Tutta la parte dedicata al machine learning (regressione + classificazione) verrà scritta qui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b05087f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Supporto_ML'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-8eafbbe89b2d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m# custom lib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mSupporto_ML\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msupp_ML\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'Supporto_ML'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "# funzioni di sk-learn\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, cross_validate\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, RobustScaler\n",
    "from sklearn.metrics import matthews_corrcoef, r2_score, accuracy_score, confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# custom lib\n",
    "import Supporto_ML as supp_ML\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4c2d242",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Prima task: prevedere l'attività di twitter a livello provinciale\n",
    "\"\"\"\n",
    "\n",
    "# Importo i dati dal database finale (vedi Import Dati)\n",
    "data = pd.read_csv('data/processed/MachineLearningDB.csv')\n",
    "\n",
    "# Smisto target e features\n",
    "target_mattina = data['TargetDay']\n",
    "target_sera = data['TargetNight']\n",
    "data.drop(columns=['TargetDay', 'TargetNight'], inplace=True)\n",
    "\n",
    "#data.drop(columns=['Weekday'], inplace=True)\n",
    "\n",
    "#Restringere database di features, molte delle features ipotizzate contano poco\n",
    "\"\"\"\n",
    "data=data[[\"Tweet1m\", \"Tavg1m\", \"Rainmax1m\", \"Rainavg1m\", \"Electro1m\", \"Tweet1n\", \n",
    "           \"Tavg1n\", \"Rainmax1n\", \"Rainavg1n\", \"Electro1n\"]]\n",
    "           \n",
    "\"\"\"\n",
    "data=data[[\"Tweet1m\", \"Tweet2m\", \"Tweet1n\", \"Tweet2n\"]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3da84e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day\n",
      "Logistic regression r2_score = -0.12457917714277733\n",
      "Evening\n",
      "Logistic regression r2_score = 0.12481486892326099\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('regressor', LogisticRegression())])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regressor (a livello regionale)\n",
    "print(\"Day\")\n",
    "supp_ML.logistic_regressor_fittato(data, target_mattina)\n",
    "print(\"Evening\")\n",
    "supp_ML.logistic_regressor_fittato(data, target_sera)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6ac70f",
   "metadata": {},
   "source": [
    "# Osservazioni:\n",
    "1) Altissima varianza valore r2, ho molti pochi dati per fare questa stima (also, ci sono i dati del fine anno e delle feste che sballano tutto) \\\n",
    "2) Rimuovere features aiuta abbastanza \\\n",
    "3) Includere il weekday **sembra** peggiorare la stima (probabilmente dovuto al fatto che finchè non lo fixiamo il one-hot-encoder hitta alcune colonne di numeri interi\n",
    "\n",
    "Overall sembra che il predittore sia better-than random usando come features solo numero di tweets dei giorni precendenti, ma si trova comunque lontano da un buon predittore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cb3f66c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest r2_score =  0.12764175814188095\n",
      "Fitting 3 folds for each of 432 candidates, totalling 1296 fits\n",
      "Random forest r2_score =  0.13423090662168358\n",
      "Random forest r2_score =  0.02151156262086995\n",
      "Fitting 3 folds for each of 432 candidates, totalling 1296 fits\n",
      "Random forest r2_score =  0.03665729974921428\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('encoder',\n",
       "                 OneHotEncoder(handle_unknown='ignore', sparse=False)),\n",
       "                ('scaler', StandardScaler()),\n",
       "                ('Regressor', RandomForestRegressor(bootstrap=False))])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest Regressor\n",
    "supp_ML.Random_Forest_Regressor_CV(data, target_mattina)\n",
    "supp_ML.Random_Forest_Regressor_CV(data, target_sera)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "543c2a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CENTRO STORICO PIEDICASTELLO', 'OLTREFERSINA', 'CENTRO STORICO PIEDICASTELLO', 'CENTRO STORICO PIEDICASTELLO', 'CENTRO STORICO PIEDICASTELLO', 'CENTRO STORICO PIEDICASTELLO', 'CENTRO STORICO PIEDICASTELLO', 'CENTRO STORICO PIEDICASTELLO', 'CENTRO STORICO PIEDICASTELLO', 'OLTREFERSINA', 'CENTRO STORICO PIEDICASTELLO', 'CENTRO STORICO PIEDICASTELLO', 'CENTRO STORICO PIEDICASTELLO', 'CENTRO STORICO PIEDICASTELLO', 'CENTRO STORICO PIEDICASTELLO', 'CENTRO STORICO PIEDICASTELLO', 'CENTRO STORICO PIEDICASTELLO', 'CENTRO STORICO PIEDICASTELLO', 'CENTRO STORICO PIEDICASTELLO', 'CENTRO STORICO PIEDICASTELLO', 'CENTRO STORICO PIEDICASTELLO', 'CENTRO STORICO PIEDICASTELLO', 'CENTRO STORICO PIEDICASTELLO', 'OLTREFERSINA', 'CENTRO STORICO PIEDICASTELLO', 'OLTREFERSINA', 'CENTRO STORICO PIEDICASTELLO', 'OLTREFERSINA', 'OLTREFERSINA', 'CENTRO STORICO PIEDICASTELLO', 'CENTRO STORICO PIEDICASTELLO', 'CENTRO STORICO PIEDICASTELLO', 'CENTRO STORICO PIEDICASTELLO', 'OLTREFERSINA', 'CENTRO STORICO PIEDICASTELLO', 'CENTRO STORICO PIEDICASTELLO', 'CENTRO STORICO PIEDICASTELLO', 'CENTRO STORICO PIEDICASTELLO', 'CENTRO STORICO PIEDICASTELLO', 'OLTREFERSINA', 'CENTRO STORICO PIEDICASTELLO', 'CENTRO STORICO PIEDICASTELLO', 'CENTRO STORICO PIEDICASTELLO', 'CENTRO STORICO PIEDICASTELLO', 'CENTRO STORICO PIEDICASTELLO', 'OLTREFERSINA', 'CENTRO STORICO PIEDICASTELLO', 'OLTREFERSINA', 'CENTRO STORICO PIEDICASTELLO', 'CENTRO STORICO PIEDICASTELLO', 'CENTRO STORICO PIEDICASTELLO', 'OLTREFERSINA', 'OLTREFERSINA', 'OLTREFERSINA', 'CENTRO STORICO PIEDICASTELLO', 'CENTRO STORICO PIEDICASTELLO', 'CENTRO STORICO PIEDICASTELLO', 'CENTRO STORICO PIEDICASTELLO', 'CENTRO STORICO PIEDICASTELLO', 'CENTRO STORICO PIEDICASTELLO', 'CENTRO STORICO PIEDICASTELLO']\n",
      "Fitting 3 folds for each of 432 candidates, totalling 1296 fits\n",
      "Lo score della nostra Random Forest risulta essere: -0.5555555555555556 per il riconoscimento delle circoscrizioni più attive\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Adesso mi occupo di fare la parte di classificazione: voglio individuare quali siano le circoscrizioni di Trento che hanno\n",
    "il più alto numero di interazioni sociali basandomi sui dati delle giornate precedenti. \n",
    "Il dataset sarà uguale a quello precedente con la differenza che la parte di conteggi delle X sarà divisa per circoscrizione\n",
    "Dal momento che ci sono 12 circoscrizioni i parametri di input saranno \n",
    "[interazioni sociali giorno i-2 divisi per circoscrizione][interazioni sociali giorno i-1 divisi per circoscrizione] + altri parametri\n",
    "Per quanto riguarda i target, considereremo la circoscrizione con il maggior numero di tweets.\n",
    "Inizialmente provo a lavorare con un Classificatore random forest, dal momento che abbiamo pochi elementi\n",
    "\"\"\"\n",
    "# Random Forest Classifier\n",
    "supp_ML.Random_Forest_Classifier_Circoscrizione(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a621a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59accfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c527f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
