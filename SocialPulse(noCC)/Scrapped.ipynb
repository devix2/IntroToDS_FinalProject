{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1039eb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ADMINISTRATIVE REGIONS\n",
    "adm_reg=m_d.safe_import(\"adm_reg\")\n",
    "adm_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f47ac88",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-ceed57e67cd9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \"\"\"\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0madm_reg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madm_reg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'items'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0madm_reg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "#Vediamo cosa contiene e come è importato\n",
    "\n",
    "\"\"\"\n",
    "#Opzioni di prints per i dataframe panda per visualizzare intere righe\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "print(adm_reg.loc[[0]])     #E' chiaro che molte delle info sono contenute nella colonna 2 che è una mappa non svolta\n",
    "print(adm_reg.count)        #Questi valori sono tutti uguali\n",
    "#Visto che anche la terza colonna ci è inutile, l'effettivo database consiste nello svolgere la colonna 2\n",
    "\"\"\"\n",
    "\n",
    "adm_reg=pd.DataFrame(list(adm_reg['items']))\n",
    "adm_reg.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be99d39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "df=pd.read_csv(\"data/processed/twitter_final.csv\")\n",
    "df=df.drop(\"geometry\", axis=1, inplace=False)\n",
    "\n",
    "tweets_json = json.load( open(m_d.data_path / m_d.files['twitter'][0]) )\n",
    "tweets = gpd.GeoDataFrame(tweets_json['features'])\n",
    "\n",
    "\n",
    "df[\"geomPoint.geom\"]=tweets[\"geomPoint.geom\"]\n",
    "tweets = gpd.GeoDataFrame(tweets_json['features'])\n",
    "\n",
    "df.to_csv(\"data/processed/twitter_final.csv\",index=False)\n",
    "\n",
    " #with open('data/processed/twitter_final.geojson', 'w') as f:\n",
    " #   f.write(df.to_json())\n",
    "  \n",
    "df\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e26e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "col=[\"month\",\"day\",\"hours\",\"temperature\", \"rain\", \"geometry\" ]\n",
    "#Visto che l'ora di tempo non è una quantità che correla a qualcosa di ciclico effettivamente misurabile*, ha poco senso\n",
    "#separare ore e minuti ed quindi tanto vale trattarli insieme\n",
    "#*Assumeremo eventi quali la campanella dei ragazzi delle superiori non influenzi in maniera importante i dati\n",
    "\n",
    "Tw_final=pd.DataFrame(columns=col)\n",
    "\n",
    "N=len(tweets[\"created\"])  #Numero tweets\n",
    "\n",
    "for i in range(0,N):\n",
    "    #Inizializzo riga o crasha\n",
    "    Tw_final.loc[i]=\"NaN\"\n",
    "    \n",
    "    #Tempo\n",
    "    #Tw_final.loc[i][\"year\"]=int(tweets.loc[i][\"created\"][0:4])  #Chemmifrega dell'anno, tutti uguali\n",
    "    Tw_final.loc[i][\"month\"]=int(tweets.loc[i][\"created\"][5:7])\n",
    "    Tw_final.loc[i][\"day\"]=int(tweets.loc[i][\"created\"][8:10])\n",
    "    Tw_final.loc[i][\"hours\"]=int(tweets.loc[i][\"created\"][11:13])+0.5*(int(tweets.loc[i][\"created\"][14:16])>=30)\n",
    "    \n",
    "    \n",
    "    # Temperatura e precipitazioni\n",
    "    # per ricavare queste usiamo la stazione più vicina al tweet\n",
    "    # (sfortunamente il Trentino non ne ha tante, fortunatamente sono distribuite bene)\n",
    "    dmin=10000000000\n",
    "    staz=\"NaN\"\n",
    "\n",
    "    for idx,stt in stations.iterrows():\n",
    "        d=tweets.loc[i][\"geometry\"].distance(stt[\"geometry\"])\n",
    "        if(d<dmin):\n",
    "            dmin=d\n",
    "            staz=stt[\"station\"]\n",
    "    \n",
    "    Tw_final.loc[i][\"temperature\"]=m_d.find_temperature(weather, Tw_final.loc[i][\"month\"],\n",
    "                                                        Tw_final.loc[i][\"day\"], Tw_final.loc[i][\"hours\"], staz)\n",
    "    Tw_final.loc[i][\"rain\"]=m_d.find_precipitation(weather, Tw_final.loc[i][\"month\"],\n",
    "                                                    Tw_final.loc[i][\"day\"], Tw_final.loc[i][\"hours\"], staz)\n",
    "    \n",
    "###!!!!!!! Ci impega molto, trovare stazione più vicina è lento\n",
    "\n",
    "\n",
    "Tw_final[\"municipal\"]=tweets[\"municipality.name\"]\n",
    "\n",
    "\n",
    "tttt = gpd.GeoDataFrame(tweets_json['features'])\n",
    "Tw_final[\"geompoint.geom\"]=tttt[\"geompoint.geom\"]  #Meglio tenerlo non svolto, così è facile da importare\n",
    "\n",
    "\"\"\"\n",
    "    PROBLEMA: Geopandas ha un bug con l'esportazione verso geojson (ironic)\n",
    "    Fare tutto in csv funziona\n",
    "\"\"\"\n",
    "\n",
    "#Salviamo infine il database\n",
    "Tw_final.to_csv('data/processed/twitter_final.csv',index=False)\n",
    "\n",
    "Tw_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b641b66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vediamo cosa contiene e come è importato\n",
    "\n",
    "\"\"\"\n",
    "#ADMINISTRATIVE REGIONS\n",
    "adm_reg=m_d.safe_import(\"adm_reg\")\n",
    "\n",
    "#Opzioni di prints per i dataframe panda per visualizzare intere righe\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "print(adm_reg.loc[[0]])     #E' chiaro che molte delle info sono contenute nella colonna 2 che è una mappa non svolta\n",
    "print(adm_reg.count)        #Questi valori sono tutti uguali\n",
    "#Visto che anche la terza colonna ci è inutile, l'effettivo database consiste nello svolgere la colonna 2\n",
    "\"\"\"\n",
    "#anche qui metadati\n",
    "admreg_json = json.load( open(m_d.data_path / m_d.files['adm_reg'][0]) )\n",
    "\n",
    "adm_reg = gpd.GeoDataFrame(admreg_json['items'])\n",
    "\n",
    "adm_reg.drop(columns=['euroCode', 'website', 'cadastralCode', 'acheneID',\n",
    "                      'wikipedia', 'isProvinceCheflieu', 'provenance',\n",
    "                      'parentAchenes', 'postCodes', 'geomComplex', 'localCode',\n",
    "                      'alternateNames', 'isMountainMunicipality'], inplace=True)\n",
    "\"\"\"\n",
    "#Creiamo il punto smontando la casella point\n",
    "tweets['geometry'] = tweets['geomPoint.geom'].apply(lambda x:Point(x['coordinates'][0], x['coordinates'][1]))\n",
    "tweets.drop(columns=['geomPoint.geom'],inplace=True)\n",
    "\n",
    "\n",
    "tweets.plot(\"municipality.name\")\n",
    "print(tweets.shape)\n",
    "#tweets.dtypes\n",
    "tweets.head(10)\n",
    "adm_reg=pd.DataFrame(list(adm_reg['items']))\n",
    "adm_reg.head(5)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#adm_reg=adm_reg[adm_reg[\"geometry\"] != adm_reg.loc[1183,:][\"geometry\"]]\n",
    "adm_reg.dropna(subset=[\"geometry\"],inplace=True, axis=0)\n",
    "\n",
    "#for i in range(0, len(adm_reg)):\n",
    "#    print(list(adm_reg[\"geometry\"][i]['coordinates']))\n",
    "print(list(adm_reg[\"geometry\"]))\n",
    "\n",
    "#Svolgo geometria\n",
    "adm_reg['geometry'] = adm_reg['geometry'].apply(\n",
    "    lambda x:Polygon(x['coordinates']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a6e741",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22d803d7",
   "metadata": {},
   "source": [
    "## MUNICIPALITA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "114825d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'm_d' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-fefa3e42564c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0madm_reg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mm_d\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msafe_import\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'regions'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0madm_reg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Shape_Area\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0madm_reg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'm_d' is not defined"
     ]
    }
   ],
   "source": [
    "adm_reg=m_d.safe_import('regions')\n",
    "\n",
    "adm_reg.plot(\"Shape_Area\")\n",
    "adm_reg.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2da08a30",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'adm_reg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-67463f3becaf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Convertiamo alla vera patria\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0madm_reg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0madm_reg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0madm_reg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"COD_PROV\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m22\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0madm_reg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Shape_Area\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'adm_reg' is not defined"
     ]
    }
   ],
   "source": [
    "#Convertiamo alla vera patria\n",
    "adm_reg=adm_reg[adm_reg[\"COD_PROV\"]==22]\n",
    "adm_reg.plot(\"Shape_Area\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c656a916",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "094a3fea",
   "metadata": {},
   "source": [
    "## NOTE PER RIALLACCIARE I DATI:\n",
    "I dati vanno riallacciati mediante appropriata conversione, dovrò\n",
    "1) Discretizzare il tempo, scegliere un tempo base per fare un binning dei dati  \\\n",
    "2) Collegare tramite la grid i dati ad un punto del plot  (binning su posizioni) \\\n",
    "3) Svolgo la divisione in minuti della tabella weather, dovrò abbastanza binnare comunque \\\n",
    "4) Svolgo i tweets vanno binnati agli intervalli temporali\n",
    "\n",
    "Alt: creo una funzione temperatura che sia continua (connetto linearmente punti distanti 15 minuti, non dovrebbero cambiar molto), e poi tratto il tempo continuo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
